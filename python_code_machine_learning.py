# -*- coding: utf-8 -*-
"""python code- machine learning

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bwn1QkVKFRP_UFJWsXyDnmUuzrVAF7X1
"""

pip install six

pip install pandas dictionary

# Importing Libraries

import numpy as np 
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Classifier Libraries
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import collections


# Other Libraries
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline
from imblearn.under_sampling import NearMiss
from imblearn.metrics import classification_report_imbalanced
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report
from collections import Counter
from sklearn.model_selection import KFold, StratifiedKFold
import warnings
warnings.filterwarnings("ignore")

dataframe = pd.read_csv('sample_data/creditcard.csv')
dataframe.head()

dataframe.describe()

#no null values
dataframe.isnull().sum().max()

dataframe.columns

# The classes are skewed heavily.
print('No Frauds', round(dataframe['Class'].value_counts()[0]/len(dataframe) * 100,2), '% of the dataset')
print('Frauds', round(dataframe['Class'].value_counts()[1]/len(dataframe) * 100,2), '% of the dataset')

colors = ["#df0101", "#df7001"]
sns.countplot('Class', data=dataframe, palette=colors)
plt.title('Distributions of Class \n (0: No Fraud || 1: Fraud)', fontsize=14)

fig, ax = plt.subplots(1, 2, figsize=(19,5))

amount_val = dataframe['Amount'].values
time_val = dataframe['Time'].values

sns.distplot(amount_val, ax=ax[0], color='b')
ax[0].set_title('Transaction Amount Distributions', fontsize=15)
ax[0].set_xlim([min(amount_val), max(amount_val)])

sns.distplot(time_val, ax=ax[1], color='g')
ax[1].set_title('Transaction Time Distributions', fontsize=15)
ax[1].set_xlim([min(time_val), max(time_val)])


plt.show()

# As most of our data has already been scaled
# now scaling the columns that are left to scale which is Amount and Time
from sklearn.preprocessing import StandardScaler, RobustScaler

# RobustScaler is less vulnerable to outliers.

std_scaler = StandardScaler()
rob_scaler = RobustScaler()

dataframe['amount_scaled'] = rob_scaler.fit_transform(dataframe['Amount'].values.reshape(-1,1))
dataframe['time_scaled'] = rob_scaler.fit_transform(dataframe['Time'].values.reshape(-1,1))

dataframe.drop(['Time','Amount'], axis=1, inplace=True)

amount_scaled = dataframe['amount_scaled']
time_scaled = dataframe['time_scaled']

dataframe.drop(['amount_scaled', 'time_scaled'], axis=1, inplace=True)
dataframe.insert(0, 'amount_scaled', amount_scaled )
dataframe.insert(1, 'time_scaled', time_scaled )
# Scaled (Amount and Time) 
dataframe.head()

from sklearn.model_selection import train_test_split
from sklearn.model_selection import StratifiedShuffleSplit

print('No Frauds', round(dataframe['Class'].value_counts()[0]/len(dataframe) * 100,2), '% of the dataset')
print('Frauds', round(dataframe['Class'].value_counts()[1]/len(dataframe) * 100,2), '% of the dataset')

x = dataframe.drop('Class', axis=1)
y = dataframe['Class']

sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)

for train_index, test_index in sss.split(x, y):
    print("Train:", train_index, "Test:", test_index)
    original_xtrain, original_xtest = x.iloc[train_index], x.iloc[test_index]
    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]


# Turning into an array
original_xtrain = original_xtrain.values
original_xtest = original_xtest.values
original_ytrain = original_ytrain.values
original_ytest = original_ytest.values

# checking if both the train and test label are distributed similarly
train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)
test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)
print('-' * 100)

print('Distributions of label: \n')
print(train_counts_label/ len(original_ytrain))
print(test_counts_label/ len(original_ytest))

dataframe = dataframe.sample(frac=1)

fraud_dataframe = dataframe.loc[dataframe['Class'] == 1]
non_fraud_dataframe = dataframe.loc[dataframe['Class'] == 0][:492]

normal_distributed_dataframe = pd.concat([fraud_dataframe, non_fraud_dataframe])

# Shuffling dataframe rows
new_dataframe = normal_distributed_dataframe.sample(frac=1, random_state=42)

new_dataframe.head()

print('Classes Distribution in the subsample dataset')
print(new_dataframe['Class'].value_counts()/len(new_dataframe))

sns.countplot('Class', data=new_dataframe, palette=colors)
plt.title('Distributed Classes equally', fontsize=16)
plt.show()

f, (ax1, ax2) = plt.subplots(2, 1, figsize=(22,19))

# whole DataFrame
corr = dataframe.corr()
sns.heatmap(corr, cmap='viridis', annot_kws={'size':21}, ax=ax1)
ax1.set_title("Correlation Matrix (Imbalanced)", fontsize=16)


sub_sample_corr = new_dataframe.corr()
sns.heatmap(sub_sample_corr, cmap='viridis', annot_kws={'size':21}, ax=ax2)
ax2.set_title('Correlation Matrix(subsample)', fontsize=16)
plt.show()

f, axes = plt.subplots(ncols=4, figsize=(22,5))

# Negative Correlations
sns.boxplot(x="Class", y="V14", data=new_dataframe, palette=colors, ax=axes[0])
axes[0].set_title('V14 vs Negative Correlation(Class)')

sns.boxplot(x="Class", y="V12", data=new_dataframe, palette=colors, ax=axes[1])
axes[1].set_title('V12 vs Negative Correlation(Class)')

sns.boxplot(x="Class", y="V10", data=new_dataframe, palette=colors, ax=axes[2])
axes[2].set_title('V10 vs Negative Correlation(Class)')

sns.boxplot(x="Class", y="V17", data=new_dataframe, palette=colors, ax=axes[3])
axes[3].set_title('V17 vs Negative Correlation(Class)')

plt.show()

f, axes = plt.subplots(ncols=4, figsize=(22,5))

# Positive correlations
sns.boxplot(x="Class", y="V2", data=new_dataframe, palette=colors, ax=axes[0])
axes[0].set_title('V2 vs Positive Correlation(Class)')

sns.boxplot(x="Class", y="V4", data=new_dataframe, palette=colors, ax=axes[1])
axes[1].set_title('V4 vs Positive Correlation(Class)')


sns.boxplot(x="Class", y="V11", data=new_dataframe, palette=colors, ax=axes[2])
axes[2].set_title('V11 vs Positive Correlation(Class)')


sns.boxplot(x="Class", y="V19", data=new_dataframe, palette=colors, ax=axes[3])
axes[3].set_title('V19 vs Positive Correlation(Class)')

plt.show()

from scipy.stats import norm

f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(22, 8))

v14_fraud_dist = new_dataframe['V14'].loc[new_dataframe['Class'] == 1].values
sns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#8B4789')
ax1.set_title('Distribution of V14 \n (Fraud Transactions)', fontsize=16)

v12_fraud_dist = new_dataframe['V12'].loc[new_dataframe['Class'] == 1].values
sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#ACB1C3')
ax2.set_title('Distribution of V12 \n (Fraud Transactions)', fontsize=16)


v10_fraud_dist = new_dataframe['V10'].loc[new_dataframe['Class'] == 1].values
sns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#e19f9f')
ax3.set_title('Distribution of V10 \n (Fraud Transactions)', fontsize=16)

plt.show()

# Removing Outliers of V14 
v14_fraud = new_dataframe['V14'].loc[new_dataframe['Class'] == 1].values
q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)
print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))
v14_iqr = q75 - q25
print('iqr: {}'.format(v14_iqr))

v14_cut_off = v14_iqr * 1.5
v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off
print('Cut Off: {}'.format(v14_cut_off))
print('V14 Lower: {}'.format(v14_lower))
print('V14 Upper: {}'.format(v14_upper))

outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]
print('V14 feature Outliers for Fraud Cases: {}'.format(len(outliers)))
print('V10 outliers:{}'.format(outliers))

new_dataframe = new_dataframe.drop(new_dataframe[(new_dataframe['V14'] > v14_upper) | (new_dataframe['V14'] < v14_lower)].index)
print('----' * 44)

# removing outliers of V12 from fraud transactions
v12_fraud = new_dataframe['V12'].loc[new_dataframe['Class'] == 1].values
q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)
v12_iqr = q75 - q25

v12_cut_off = v12_iqr * 1.5
v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off
print('V12 Lower: {}'.format(v12_lower))
print('V12 Upper: {}'.format(v12_upper))
outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]
print('V12 outliers: {}'.format(outliers))
print('V12 feature Outliers for Fraud Cases: {}'.format(len(outliers)))
new_dataframe = new_dataframe.drop(new_dataframe[(new_dataframe['V12'] > v12_upper) | (new_dataframe['V12'] < v12_lower)].index)
print('Number of Instances after outliers removal: {}'.format(len(new_dataframe)))
print('----' * 44)


# Removing outliers of V10 
v10_fraud = new_dataframe['V10'].loc[new_dataframe['Class'] == 1].values
q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)
v10_iqr = q75 - q25

v10_cut_off = v10_iqr * 1.5
v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off
print('V10 Lower: {}'.format(v10_lower))
print('V10 Upper: {}'.format(v10_upper))
outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]
print('V10 outliers: {}'.format(outliers))
print('V10 feature Outliers for Fraud Cases: {}'.format(len(outliers)))
new_dataframe = new_dataframe.drop(new_dataframe[(new_dataframe['V10'] > v10_upper) | (new_dataframe['V10'] < v10_lower)].index)
print('Number of Instances after outliers removal: {}'.format(len(new_dataframe)))

f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(22,8))

colors = ['#2b9093', '#e19f9f']

# V14 Feature
sns.boxplot(x="Class", y="V14", data=new_dataframe,ax=ax1, palette=colors)
ax1.set_title("Feature V14 \n outliers Reduction", fontsize=16)
ax1.annotate('Fewer extreme \n outliers', xy=(0.98, -17.5), xytext=(0, -12),
            arrowprops=dict(facecolor='black'),
            fontsize=16)

# V12 Feature
sns.boxplot(x="Class", y="V12", data=new_dataframe, ax=ax2, palette=colors)
ax2.set_title("Feature V12 \n outliers Reduction", fontsize=16)
ax2.annotate('Fewer extreme \n outliers', xy=(0.98, -17.3), xytext=(0, -12),
            arrowprops=dict(facecolor='black'),
            fontsize=16)

# V10 Feature
sns.boxplot(x="Class", y="V10", data=new_dataframe, ax=ax3, palette=colors)
ax3.set_title("Feature V10 \n outliers Reduction", fontsize=16)
ax3.annotate('Fewer extreme \n outliers', xy=(0.95, -16.5), xytext=(0, -12),
            arrowprops=dict(facecolor='blue'),
            fontsize=16)


plt.show()

# Undersampling 
x = new_dataframe.drop('Class', axis=1)
y = new_dataframe['Class']

# splitting training and test sets
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Turning the values into an array
x_train = x_train.values
x_test = x_test.values
y_train = y_train.values
y_test = y_test.values

# Implementing simple classifiers

classifiers = {
    "LogisiticRegression": LogisticRegression(),
    "KNearest": KNeighborsClassifier(),
    "Support Vector Classifier": SVC(),
    "DecisionTreeClassifier": DecisionTreeClassifier()
}

from sklearn.model_selection import cross_val_score


for key, classifier in classifiers.items():
    classifier.fit(x_train, y_train)
    training_score = cross_val_score(classifier, x_train, y_train, cv=5)
    print("Classifiers: ", classifier.__class__.__name__, "has a training score of", round(training_score.mean(), 2) * 100, "% accuracy score")

# Using GridSearchCV 
from sklearn.model_selection import GridSearchCV


# Logistic Regression 
log_reg_params = {"penalty": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}



grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params)
grid_log_reg.fit(x_train, y_train)
log_reg = grid_log_reg.best_estimator_

knears_params = {"n_neighbors": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}

grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params)
grid_knears.fit(x_train, y_train)
# KNears estimator
knears_neighbors = grid_knears.best_estimator_

# Classifier (Support Vector)
svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}
grid_svc = GridSearchCV(SVC(), svc_params)
grid_svc.fit(x_train, y_train)

# SVC estimator
svc = grid_svc.best_estimator_

# Classifier (DecisionTree)
tree_params = {"criterion": ["gini", "entropy"], "max_depth": list(range(2,4,1)), 
              "min_samples_leaf": list(range(5,7,1))}
grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params)
grid_tree.fit(x_train, y_train)

# tree estimator
tree_clf = grid_tree.best_estimator_

# Overfitting 

log_reg_score = cross_val_score(log_reg, x_train, y_train, cv=5)
print('Cross Validation Score of Logistic Regression: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')


knears_score = cross_val_score(knears_neighbors, x_train, y_train, cv=5)
print('Cross Validation Score of Knears Neighbors', round(knears_score.mean() * 100, 2).astype(str) + '%')

svc_score = cross_val_score(svc, x_train, y_train, cv=5)
print('Classifier Cross Validation Score of Support Vector', round(svc_score.mean() * 100, 2).astype(str) + '%')

tree_score = cross_val_score(tree_clf, x_train, y_train, cv=5)
print('Classifier Cross Validation Score of DecisionTree', round(tree_score.mean() * 100, 2).astype(str) + '%')

# undersampling during cross validating
undersample_x = dataframe.drop('Class', axis=1)
undersample_y = dataframe['Class']

for train_index, test_index in sss.split(undersample_x, undersample_y):
    print("Train:", train_index, "Test:", test_index)
    undersample_xtrain, undersample_xtest = undersample_x.iloc[train_index], undersample_x.iloc[test_index]
    undersample_ytrain, undersample_ytest = undersample_y.iloc[train_index], undersample_y.iloc[test_index]
    
undersample_xtrain = undersample_xtrain.values
undersample_xtest = undersample_xtest.values
undersample_ytrain = undersample_ytrain.values
undersample_ytest = undersample_ytest.values 

undersample_accuracy = []
undersample_precision = []
undersample_recall = []
undersample_f1 = []
undersample_auc = []

# Implementing NearMiss Technique
x_nearmiss, y_nearmiss = NearMiss().fit_sample(undersample_x.values, undersample_y.values)
print('Label Distribution of NearMiss: {}'.format(Counter(y_nearmiss)))

for train, test in sss.split(undersample_xtrain, undersample_ytrain):
    undersample_pipeline = imbalanced_make_pipeline(NearMiss(sampling_strategy='majority'), log_reg) 
    undersample_model = undersample_pipeline.fit(undersample_xtrain[train], undersample_ytrain[train])
    undersample_prediction = undersample_model.predict(undersample_xtrain[test])
    
    undersample_accuracy.append(undersample_pipeline.score(original_xtrain[test], original_ytrain[test]))
    undersample_precision.append(precision_score(original_ytrain[test], undersample_prediction))
    undersample_recall.append(recall_score(original_ytrain[test], undersample_prediction))
    undersample_f1.append(f1_score(original_ytrain[test], undersample_prediction))
    undersample_auc.append(roc_auc_score(original_ytrain[test], undersample_prediction))

# Plotting LogisticRegression Learning Curve
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import learning_curve

def plot_learning_curve(estimator1, estimator2, estimator3, estimator4, x, y, ylim=None, cv=None,
                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):
    f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(22,16), sharey=True)
    if ylim is not None:
        plt.ylim(*ylim)
    # 1st Estimator
    train_sizes, train_scores, test_scores = learning_curve(
        estimator1, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    ax1.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="#548b54")
    ax1.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="#ff9124")
    ax1.plot(train_sizes, train_scores_mean, 'o-', color="#548b54",
             label="Training score")
    ax1.plot(train_sizes, test_scores_mean, 'o-', color="#ff9124",
             label="Cross-validation score")
    ax1.set_title("Learning Curve of Logistic Regression", fontsize=14)
    ax1.set_xlabel('Training size (m)')
    ax1.set_ylabel('Score')
    ax1.grid(True)
    ax1.legend(loc="best")
    
    # 2nd Estimator 
    train_sizes, train_scores, test_scores = learning_curve(
        estimator2, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    ax2.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="#548b54")
    ax2.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="#ff9124")
    ax2.plot(train_sizes, train_scores_mean, 'o-', color="#548b54",
             label="Training score")
    ax2.plot(train_sizes, test_scores_mean, 'o-', color="#ff9124",
             label="Cross-validation score")
    ax2.set_title("Learning Curve of Knears Neighbors", fontsize=14)
    ax2.set_xlabel('Training size (m)')
    ax2.set_ylabel('Score')
    ax2.grid(True)
    ax2.legend(loc="best")
    
    # 3rd Estimator
    train_sizes, train_scores, test_scores = learning_curve(
        estimator3, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    ax3.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="#548b54")
    ax3.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="#ff9124")
    ax3.plot(train_sizes, train_scores_mean, 'o-', color="#548b54",
             label="Training score")
    ax3.plot(train_sizes, test_scores_mean, 'o-', color="#ff9124",
             label="Cross-validation score")
    ax3.set_title("Classifier of Support Vector \n Learning Curve", fontsize=14)
    ax3.set_xlabel('Training size (m)')
    ax3.set_ylabel('Score')
    ax3.grid(True)
    ax3.legend(loc="best")
    
    # 4th Estimator
    train_sizes, train_scores, test_scores = learning_curve(
        estimator4, x, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)
    train_scores_mean = np.mean(train_scores, axis=1)
    train_scores_std = np.std(train_scores, axis=1)
    test_scores_mean = np.mean(test_scores, axis=1)
    test_scores_std = np.std(test_scores, axis=1)
    ax4.fill_between(train_sizes, train_scores_mean - train_scores_std,
                     train_scores_mean + train_scores_std, alpha=0.1,
                     color="#548b54")
    ax4.fill_between(train_sizes, test_scores_mean - test_scores_std,
                     test_scores_mean + test_scores_std, alpha=0.1, color="#ff9124")
    ax4.plot(train_sizes, train_scores_mean, 'o-', color="#548b54",
             label="Training score")
    ax4.plot(train_sizes, test_scores_mean, 'o-', color="#ff9124",
             label="Cross-validation score")
    ax4.set_title("Classifier of Decision Tree \n Learning Curve", fontsize=14)
    ax4.set_xlabel('Training size (m)')
    ax4.set_ylabel('Score')
    ax4.grid(True)
    ax4.legend(loc="best")
    return plt

cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=42)
plot_learning_curve(log_reg, knears_neighbors, svc, tree_clf, x_train, y_train, (0.87, 1.01), cv=cv, n_jobs=4)

from sklearn.metrics import roc_curve
from sklearn.model_selection import cross_val_predict
# Creating a DataFrame with all the classifiers names and the scores.

log_reg_pred = cross_val_predict(log_reg, x_train, y_train, cv=5,
                             method="decision_function")

knears_pred = cross_val_predict(knears_neighbors, x_train, y_train, cv=5)

svc_pred = cross_val_predict(svc, x_train, y_train, cv=5,
                             method="decision_function")

tree_pred = cross_val_predict(tree_clf, x_train, y_train, cv=5)

from sklearn.metrics import roc_auc_score

print('Logistic Regression: ', roc_auc_score(y_train, log_reg_pred))
print('KNears Neighbors: ', roc_auc_score(y_train, knears_pred))
print('Support Vector Classifier: ', roc_auc_score(y_train, svc_pred))
print('Decision Tree Classifier: ', roc_auc_score(y_train, tree_pred))

log_fpr, log_tpr, log_thresold = roc_curve(y_train, log_reg_pred)
knear_fpr, knear_tpr, knear_threshold = roc_curve(y_train, knears_pred)
svc_fpr, svc_tpr, svc_threshold = roc_curve(y_train, svc_pred)
tree_fpr, tree_tpr, tree_threshold = roc_curve(y_train, tree_pred)


def graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr):
    plt.figure(figsize=(20,10))
    plt.title('ROC Curve \n 4 Classifiers', fontsize=18)
    plt.plot(log_fpr, log_tpr, label='Logistic Regression Classifier Score: {:.4f}'.format(roc_auc_score(y_train, log_reg_pred)))
    plt.plot(knear_fpr, knear_tpr, label='KNears Neighbors Classifier Score: {:.4f}'.format(roc_auc_score(y_train, knears_pred)))
    plt.plot(svc_fpr, svc_tpr, label='Support Vector Classifier Score: {:.4f}'.format(roc_auc_score(y_train, svc_pred)))
    plt.plot(tree_fpr, tree_tpr, label='Decision Tree Classifier Score: {:.4f}'.format(roc_auc_score(y_train, tree_pred)))
    plt.plot([0, 1], [0, 1], 'k--')
    plt.axis([-0.01, 1, 0, 1])
    plt.xlabel('False Positive Rate', fontsize=18)
    plt.ylabel('True Positive Rate', fontsize=18)
    plt.annotate('Minimum ROC Score of 50%', xy=(0.5, 0.5), xytext=(0.6, 0.3),
                arrowprops=dict(facecolor='#9aa7c1', shrink=0.05),
                )
    plt.legend()
    
graph_roc_curve_multiple(log_fpr, log_tpr, knear_fpr, knear_tpr, svc_fpr, svc_tpr, tree_fpr, tree_tpr)
plt.show()